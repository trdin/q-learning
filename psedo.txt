implemement  the q learning in jupyter notebook, use the bellmans equation to calculate new values in the learning step ,   also use epsilon greedy policy 
pseudo code for the q learning function 

PSEUDO CODE: 
initialize q- table 
for  ep in n_train_episodes:
    set the values  of  epsilon
    get  the state of environment S
    for step in max steps:
        set action A according  to  epsilon greedy policy 
        complete action A and get na new state S' with a reward
        calculate  a  new value Q(S,A) with the Bellman's equation
         if action A leads into  a cancellation then
            break
        S=S'
    end for
end for
return Q

parameters of the q learning function:
n_train_episodes - ≈†tevilo iteracij uƒçenja
lr - Stopnja uƒçenja
n_eval_episodes	- ≈†tevilo iteracij vrednotenja
max_steps -	Maksimalno ≈°tevilo korakov
gamma -	Redukcijski faktor ùõæ
min_epsilon	- minimal calue of epsilon
max_epsilon - maksimal value of epsilon
decay	Faktor v eksponentu ùõø

implement these funcitons : 
inicializacija Q tabele
epsilon greedy policy 
uƒçenje
vrednotenje

bellmans equation: 
Q(S(t), a(t)) = Q(S(t), a(t)) + lr[ r(t+1) + gamma * max( Q(s(t+1), a)) -  Q(S(t), a(t)) ]
max() - ocenjena optimalna naslenda vrednost 

epsilon greedy policy:

epsilon = epsilon(min) + (epsilon(max) - epsilon(min)) * e ^ (-decay*i)